---
title: Predicting cemented sandstone permeability with physics-based 
  and machine learning approaches
author: "Frank Male, Jerry L. Jensen, Larry W. Lake"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  word_document: 
    reference_docx: styles-ref.docx
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
require(XLConnect)
require(MASS)
require(tidyverse)
require(qqplotr)
require(ggpubr)
require(latex2exp)
require(janitor)
require(caret)
require(recipes)
require(iml)
library(reshape2)
library(ggridges)
require(dplyr)
require(doParallel)
require(xgboost)
library(knitr)
library(kableExtra)
#library(ggtern)
figdir <- "figures/"

theme_set(theme_pubr())

df <- readWorksheetFromFile("C:/Users/malef/Dropbox/ROZ/data/GARN1990.xlsx", sheet=1) %>%
  mutate_at(vars(CD:IMP), ~ as.numeric(.)) %>%
  mutate(WELL = str_trim(WELL)) %>%
  ## Replace zeros in interparticle porosity and cement content to a value below the lowest measurable quantity
  mutate(IMP = replace(IMP, IMP==0, 0.2),
         ICL  = replace(ICL, ICL==0, 0.1),
         QCM = replace(QCM, QCM==0, 0.1)) %>%
  select(WELL, KLH, POR, IMP, GS, SO, KAO, ICL, QCM, CAL, DOL) %>%
  drop_na()



porosity_cutoff <- 2.5

df_name <-readWorksheetFromFile("C:/Users/malef/Dropbox/ROZ/data/GARN1990.xlsx", sheet=2) %>%
  rename(Var1=EXPLANATION.,explanation=Col2)

erfinv <- function(x) qnorm((x + 1)/2)/sqrt(2)

df <- df %>%
  mutate(POR = POR/100,
         IM_POR = IMP/100,
         GS = GS*1e3,
         mu = log(GS),
         sigma = log(SO) / (sqrt(2) * erfinv(0.5)),
         mean_GS = exp( mu + sigma/2),
         Cv_GS = sqrt( exp( sigma^2) - 1),
         gamma_GS = (exp(sigma^2) + 2) * Cv_GS,
         tau_o = (0.9*IM_POR/(1-0.1*IM_POR))^(-0.378*2),
         tau_u = tau_o * (1+Cv_GS),
         a_o = 6 / mean_GS,
         a_u = 6* (sigma^2 + mean_GS^2)/(gamma_GS * sigma^2 + 3*mean_GS*sigma^2 + mean_GS^3),
         CK_void_fraction = IM_POR^3/(1-IM_POR)^2,
         logk = log(KLH)  
         )
#now for the perm predictions
df <-  df %>%
  mutate(k_pl94_por = (mean_GS^2 * POR^3)/(72* tau_u * (1-POR)^2) * (gamma_GS * Cv_GS^3 + 3*Cv_GS^2 + 1)^2/(1 + Cv_GS^2)^2,
         k_pl94_impor = (mean_GS^2 * IM_POR^3)/(72* tau_u * (1-IM_POR)^2) * (gamma_GS * Cv_GS^3 + 3*Cv_GS^2 + 1)^2/(1 + Cv_GS^2)^2
         )
 
df <- df %>%
  mutate(P_f = (KAO + QCM + CAL + DOL)/100,
         P_b = ICL/100,
         POR_u = IM_POR + P_f + P_b,
         m = P_f * (1-IM_POR)/IM_POR,
         m_b = P_b * (1-IM_POR)/IM_POR,
         tau_e = tau_u * (1+Cv_GS) * (1+ 2*m_b/(1-m_b))^2 * (1 + 2*m/((1-m) * IM_POR^(1/3.0)))^2,
         a_e_sorta = a_u * (1 - POR_u)/(1-IM_POR), #+ a_b*P_b + a_f*P_f
         porosity_group = if_else(IMP > porosity_cutoff, "High", "Low")
         )

set.seed(43)
holdout.wells <- sample(unique(df$WELL), size=4)
df_holdout <- filter(df, WELL %in% holdout.wells)
df <- filter(df, !WELL %in% holdout.wells)


## split between high and low phi
df_lowphi <- filter(df, porosity_group=="Low")
df_highphi <- filter(df, porosity_group!="Low")

df_holdout_lp <- filter(df_holdout, porosity_group=="Low")
df_holdout_hp <- filter(df_holdout, porosity_group!="Low")

## Building recipes
rec_obj_lp <- recipe(KLH ~ CK_void_fraction + tau_e + a_u + P_f + P_b + WELL, data=df_lowphi) %>%
  step_log(KLH) %>%
  update_role(WELL, new_role = "dataset split variable") %>%
  step_log(all_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep(training=df_lowphi, retain=TRUE)

train_lp <- bake(rec_obj_lp, df_lowphi)
test_lp <- bake(rec_obj_lp, filter(df_holdout, IMP <= porosity_cutoff)) 

rec_obj_hp <- recipe(KLH ~ CK_void_fraction + tau_e + a_u + P_f + P_b + WELL, data=df_highphi) %>%
  step_log(KLH) %>%
  update_role(WELL, new_role = "dataset split variable") %>%
  step_log(all_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep(training=df_highphi, retain=TRUE)
train_hp <- bake(rec_obj_hp, df_highphi)
test_hp <- bake(rec_obj_hp, filter(df_holdout, IMP > porosity_cutoff))

## Fit control for cross validation
fit_control_lp <- trainControl(index = groupKFold(train_lp$WELL),
                            allowParallel = TRUE)
fit_control_hp <- trainControl(index = groupKFold(train_hp$WELL),
                            allowParallel = TRUE)
```

# Abstract

# Introduction
Sandstone  is one of the most common types of reservoir rocks, contributing approximately 30% to the stratigraphic total of sedimentary rocks (Pettijohn et al., 1975). Therefore, it is of great interest to predict the reservoir properties of sandstones. In this paper, we will focus on explaining the factors that influence sandstone permeability.  
  
Two approaches are available for permeability prediction of sandstones: 1) physics-based models such as the Carman-Kozeny equation and 2) empirical models developed using statistical or machine learning tools that assume no particular physical laws linking predictors and permeability. There are a number of physics-based and empirical models; Dullien (2012) is a nice review of both model types. We will apply a hybrid approach that considers both the physical intuition encapsulated in the Carman-Kozeny equation and data-centric models.  
  
Kozeny (1927) and Carman (1937) developed an equation linking permeability to three factors: porosity, hydraulic tortuosity, and specific surface area.  Porosity and permeability are routinely measured during core analysis, but hydraulic tortuosity (as opposed to electrical tortuosity) and specific surface area are not commonly evaluated. However, tortuosity and specific surface area arise from geologic processes that can be modeled and distributed throughout the reservoir. Therefore, understanding the magnitude and effect of proxies for tortuosity and surface area can aid in building accurate porosity-permeability transformations and applying these transformations in geomodels.  
  
Panda and Lake (1995) developed a mathematical framework for estimating tortuosity and specific surface area for real rocks that had undergone diagenesis. With this framework, permeability can be predicted from the intergranular porosity, average grain diameter, grain size distribution, and the amounts of various types of cements.  
  
Machine learning is a tool that can be used to understand how useful proxies for tortuosity and specific surface area are for predicting permeability. With advanced non-parametric machine learning (such as the gradient boosting machine developed by Friedman, 2001), there is no requirement to assume _a priori_ a functional form between these proxies and the predicted quantity. With the recent derivation of a consistent feature attribution system for explaining tree-based models (Lundberg et al., 2018), the functional form can be visualized after modeling, helping petrophysicists understand the mechanisms controlling permeability.  
  
Given the physics-based model and advanced machine learning approaches, we propose a hybrid approach, combining the best qualities of each approach.  
In this study, we develop estimates for the permeability of the Garn sandstone reservoir (Ehrenberg, 1990), using the data from that study. We compare different methods for calculating the tortuosity and specific surface area from core description, and we find the most important determinants of porosity-permeability transforms in this case.

**XXX More results**

# Methods
## Physical models
Perhaps the best known physics-based approach to estimating permeability was developed by Kozeny (1927) and later modified by Carman (1937). In its modern form, the equation is written as
$$k = \frac{\phi^3}{2\tau(1-\phi)^2 a^2},$$
which, for simplicity, we will write as
$$k = \frac{\phi_{CK}}{2\tau a^2},$$
where  permeability is $k$,  porosity is $\phi$, tortuosity is $\tau$, the specific surface area is $a$, and the Carman-Kozeny void fraction is $\phi_{CK}$. For an uncemented sandstone, tortuosity can be calculated following the derivation in Appendix A, which comes from Panda and Lake (1994). For a cemented sandstone (Appendix B), the tortuosity changes because of cements blocking and forcing modification of the flow paths.  
  
For monodisperse spheres, $a=6/d$, where $d$ is the sphere diameter. For uncemented spheres of more than one size, $a$ can be estimated from the particle size distribution. After cementation, the cement distribution is important to how the surface area changes. Some cements will coat the pores walls, slightly decreasing the specific surface area. Other cements will line or bridge the pores, moderately to greatly increasing the specific surface area.  
  
A variation on the Carman-Kozeny model is the idea that pore throat sizes are the most important determinant of permeability-porosity transforms. This hypothesis is implicit in the Winland relations that follow the form
$$\ln r = A \ln k - B \ln \phi + C$$
 
where $r$ is the pore throat radius (see Kolodzie, 1980 and Di and Jensen, 2015). Winland’s work focused on predicting pore throat radius (and therefore two phase fluid flow properties) from permeability, rather than the other way around. However, in recent years, some studies use wireline log measurements to constrain the pore throat radius in order to predict permeability (see Ghanbarian et al., 2019).  
  
Doyen (1988) formalized this approach, applying effective medium theory to explain permeability with the equation  
$$k =  \frac{\phi}{8\tau}  \frac{r_{eff}^4}{\langle r_b^2\rangle}$$
where $r_{eff}$ is the effective pore throat radius and $\langle r_b^2\rangle$ is the spatial average of the square of the pore channel radii. This result is remarkably similar to the Carman-Kozeny equation, except that the dependency on specific surface area has been replaced with a dependency on the pore throat radii.  
  
As a practical consideration, the pore throat radius might be more impacted by cements that coat the walls than cements that bridge the pores. However, the opposite is true for the specific surface area (Scheidegger, 1960).

## Data-driven models
Empirical models have long been important in reservoir engineering (see Frick, 1962 for numerous examples). These models, such as Winland’s (Kolodzie, 1980), find relationships between predictor variables and responses. In the last two decades, advances in applied statistics and computing power have created new approaches for developing empirical relationships. This has spawned the field of data analytics and machine learning.  
  
The data analytics approach is as follows: a) collect and clean data b) propose predictor variables c) perform exploratory analysis d) build machine learning models e) evaluate the machine learning models on new data f) interpret model results.  
  
The data for this study comes from Ehrenberg (1990). We chose this dataset because it has large variations in permeability and porosity, cement proportions are measured, and it requires only minimal cleaning. However, it does not have all of the variables used in the Carman-Kozeny equation. Therefore, we performed feature engineering to derive these variables from Ehrenberg’s measurements. Among the variables we did not have were the mean particle size, the coefficient of variation of the particle size, and the skewness of the particle size distribution. These variables were derived through the procedure given in Appendix C.  
  
During exploratory data analysis, we plot the distributions of predictor and response variables and make cross-plots between variable pairs to identify predictor variables with high co-linearity and with strong correlation to the response variable. In this case, the predictor variables include the porosity, Carman-Kozeny void fraction, Carman-Kozeny predictions of permeability, and the amount of pore-filling and pore-bridging cement present.  
  
Ehrenberg (1990) made two estimates of the porosity. One estimate came from helium porosiometry, and the other from point counting the intergranular macroporosity of thin sections. These measurements are highly correlated, so including both in the regression model could cause overfitting and problems with determining the influence of porosity on the permeability. Therefore, we chose to use only one porosity estimate. Exploratory data analysis showed that intergranular macroporosity was a better predictor of permeability, and we chose it for the model.  
  
We used two approaches to build the models: multiple linear regression and gradient boosting regression (Friedman, 2001). Multiple linear regressions are common, easily interpretable, and robust to overfitting. These regressions also make several assumptions that are often violated in real data sets. Gradient boosting regressors make fewer assumptions about the distributions of the input data and the character of the relationship between predictor variables and the response, but are difficult to interpret and prone to overfitting. In order to illustrate the benefits and drawbacks of these approaches, we use both methods and compare the results.  
  
Through careful feature selection and pre-processing, we limited the degree to which the assumptions in linear regression are violated. As aforementioned, one of those steps is removing highly correlated predictor variables. In addition, we log-transformed the predictor variables and permeability,  which reduces non-normality of the variables’ distributions. Log-transformation also makes the correlations between variables more linear. (Using the Box-Cox (1964) transformation did not significantly improve the results, but it can be effective, as shown by Jensen et al. (1987).) 
  
We evaluated the models through calculating the model explained variance (R^2^), mean absolute error (MAE), and root-mean squared error (RMSE). Hyperparameters for the gradient boosting regressor were selected through cross-validation. These parameters were tuned in order to maximize the model effectiveness while reducing overfitting, through minimizing the validation RMSE on held-out wells.  
  
In order to determine whether predictor variables contributed to the result, we used a non-parametric approach. This approach is called Permutation Feature Importance (Fisher, et al., 2018), and estimates the importance of a predictor variable based on how much the model error increases after that variable is permutated.  
  
Linear models can be interpreted simply through examining the weight assigned to each predictor (feature). Gradient boosting methods require a different approach. Shapley Additive Explanations (SHAP values) offer a way to explain how each predictor variable contributed to each prediction (Lundberg and Lee, 2016). 

# Results
## Exploratory analysis
First, we examined the distributions for porosity, permeability, Carman-Kozeny void fraction, and the proportion of various cements (Fig. 1). The permeability, porosity---and therefore Carman-Kozeny void fraction--- distributions follow a bi-modal distribution. Therefore, when we performed regressions on the data, we treated each mode separately, rather than regressing across the entirety of the data. The data was split into samples where the interparticle macro-porosity is greater than `r porosity_cutoff`% (high) or less than or equal to `r porosity_cutoff`% (low).

```{r exploratory, fig.width=7, fig.height=5, warning=FALSE}
#Permeability Box-Cox

#bc <- boxcox(KLH ~ 1, data = df)
plot_hist <- function(x, bins = 20){
  x <- ensym(x)
  p <- ggplot(df, aes(x = !!x)) +
    geom_histogram(fill="steelblue", bins = bins) +
    annotation_logticks(sides = "b") +
    scale_y_continuous("Count", expand = c(0.001,0))
  p
}

p1 <- 
  plot_hist(KLH) +
  scale_x_log10("Permeability (mD)", breaks = c(0.1,1,10,100,1000), labels = c(0.1,1,10,100,1000))

p2 <- 
  plot_hist(IMP) +
  scale_x_log10("Interparticle macro-porosity (p.u.)", breaks = c(0.3, 1, 3, 10, 30), labels = c(0.3, 1, 3, 10, 30))


p3 <- 
  plot_hist(CK_void_fraction) +
  scale_x_log10("Carman-Kozeny void fraction") 

df_name_cements <- df_name %>%
  mutate(cement_type = gsub("([A-Za-z\\-]+).*", "\\1",explanation),
         cement_type = gsub("Non-kaolin","Non-kaolin clay", cement_type))
 df_name_cements$cement_type = factor(df_name_cements$cement_type, 
                                      levels = c("Quartz","Non-kaolin clay", "Kaolin", "Siderite",
                                                 "Pyrite","K-feldspar","Dolomite","Detrital","Calcite")
 )
p4 <- 
  df %>%
  select(KAO,ICL,QCM, DOL) %>%
  drop_na() %>%
  reshape2::melt(value.name = "Percent", measure.vars = c("KAO","ICL","QCM","DOL"))  %>% 
  merge(df_name_cements, by.x = "variable", by.y ="Var1") %>%
  #mutate(cement_type = reorder(cement_type, }))
  ggplot(aes(x=Percent, y=cement_type)) +
  geom_density_ridges(fill="steelblue", stat = "binline", binwidth = 2) +
  scale_x_continuous(limits=c(0,22), expand=c(0,0)) +
  scale_y_discrete(expand = c(0.01,0)) +
  #theme_ridges() +
  labs(x="Cement percent abundance", y="")
ggarrange(p1, p2, p3, p4, ncol = 2, nrow = 2, labels = "auto")
```

Figure 1. Histograms for the distributions of a) Klinkenberg-corrected absolute permeability b) interparticle macro-porosity from point-counting c) Carman-Kozeny void fraction from macro-porosity d) percent cement abundance for several types of cement. The permeability and porosity are log-transformed and follow bi-modal distributions. Quartz is the most abundant cement, followed by non-kaolin clay (smectite and illite).  
  
Next, we cross-plotted permeability and several predictors: Carman-Kozeny void fraction, tortuosity, pre-cementation specific surface area, and fraction of pore-bridging and pore-filling cement. Pore-filling cement includes quartz, kaolin clay, and dolomite, and pore-bridging cement is non-kaolin clay.  
```{r crossplots, fig.width=7, fig.height=7, warning=FALSE}
crossplot <- function(x){
  x <- ensym(x)
  p <- ggplot(df, aes(!!x, KLH, color = porosity_group)) +
    geom_point() +
    #scale_x_log10() +
    scale_y_log10("Permeability (mD)", breaks = c(0.1, 1, 10, 100, 1000, 10000), 
                  labels = c(0.1, 1, 10, 100, 1000, 10000))  +
    annotation_logticks(sides = "bl") +
    scale_color_manual("Porosity\ngroup", values = c("peru","steelblue"))
  
  p
}
p0 <- crossplot(IMP) +
  scale_x_log10() +
  labs(x = "Interparticle porosity")

p1 <- crossplot(CK_void_fraction) +
  scale_x_log10() +
  labs(x = "Carman-Kozeny void fraction")


p2 <- crossplot(tau_e) +
  scale_x_log10() +
  labs(x = "Tortuosity")


p3 <- crossplot(a_u) +
  scale_x_log10() +
  labs(x = "Specific surface area for grains")

p4 <- crossplot(P_b) +
  labs(x = "Pore bridging cement")+
  scale_x_log10(limits = c(0.003, 0.3))

p5 <- crossplot(P_f) +
  labs(x = "Pore filling cement") +
  scale_x_log10(limits = c(0.003, 0.3))

ggarrange(p0,p1, p2, p3, p4, p5, ncol = 2, nrow = 3, labels = "auto", legend = "right", common.legend = TRUE)
```  

Figure 2. Cross-plots between permeability and several predictor variables. These variables include a) the interparticle macro-porosity b) the Carman-Kozeny void fraction, c) tortuosity as calculated in Panda and Lake (1995), d) specific surface area  in square microns  for the grains (pre-cementation), e) fraction of pore-bridging cement f) fraction of pore-filling cement. The color indicates whether the sample has greater than `r porosity_cutoff` percent porosity (orange) or not (blue).  
  
To assign values to the correspondence between the predictor variables and permeability, we calculated the Pearson's r and Kendall tau values (Table 1). Both statistics measure the degree of association and have values between -1 and 1. Pearson’s statistic is a measure of linear correlation and based on the data values; Kendall’s statistic is based on the ranks of the data values. More details can be found in many statistics texts, including Miller (1986).  
  
Table 1. Pearson r and Kendall tau values for correlation between log-transformed predictor variables and the log of permeability. The data is split between modes of the porosity distribution, based on whether or not the porosity is greater than `r porosity_cutoff`. Tortuosity is calculated after taking cementation into account, specific surface area is calculated without including cementation.
```{r correlations}
df2 <- data.table::as.data.table(df)[,list(Permeability = KLH, 
                                           `Carman-Kozeny void fraction` = CK_void_fraction, 
                                           Tortuosity=tau_e, 
                                           `Specific surface area`=a_u, 
                                           `Pore-bridging cement`=P_b, 
                                           `Pore-filling cement`=P_f,
                                           `Porosity group`=porosity_group)]


df2 %>%
  melt(measure.vars = c("Carman-Kozeny void fraction", "Tortuosity","Specific surface area", "Pore-bridging cement", 
                        "Pore-filling cement")) %>%
  group_by(variable, `Porosity group`) %>%
  dplyr::summarize(`Pearson r` = round(cor(Permeability, value),2), 
                   `Kendall tau` = round(cor(Permeability, value, method = "kendall"), 2)) %>%
  melt(measure.vars = c("Pearson r", "Kendall tau"), variable.name = "Correlation") %>%
  dcast(`Porosity group` + Correlation ~ variable ) %>%
  kable(format="pandoc") #%>%
  #kable_styling()
```

The correlation measures between predictor variables and the permeability take on different values depending on whether the porosity is high or low. The correlations are consistently smaller at low porosity. Porosity is the most strongly correlated with permeability, with cements next, and tortuosity and specific surface area having the weakest correlations.

## Model results
We tested the accuracies and correlations between the physics-based and regression-based models and the measured permeability. There were three physics-based models of increasing complexity:  
1. Carman-Kozeny model where we assumed the grains were uncompacted  
2. Carman-Kozeny model with compaction  
3. Carman-Kozeny including compaction and  cement's effect on tortuosity   
  
The results from these models of increasing complexity are shown in Fig. 3.

```{r physics_based, fig.width=7, fig.height=5}
reg_plot <- function(df, kpred){
  kpred <- enquo(kpred)
  p <- 
    ggplot(df, aes(KLH, !!kpred, color = porosity_group)) +
    geom_point() +
    geom_smooth(method = "lm") +
    scale_x_log10("Actual permeability (mD)", breaks = c(0.1, 1, 10, 100, 1000, 10000), 
                  labels = c(0.1, 1, 10, 100, 1000, 10000)) +
    scale_y_log10("Predicted perm (mD)") +
    annotation_logticks(sides = "bl") +
    scale_color_manual("Porosity\ngroup", values = c("peru","steelblue"))
  
  p
}

p1 <- df %>%
  reg_plot(CK_void_fraction / (2 * tau_o * a_o^2)) +
  labs(title = "Unconsolidated")

p2 <- df %>%
  reg_plot(k_pl94_impor) +
  labs(title = "Including compaction")

p3 <- df %>%
  reg_plot(CK_void_fraction / (2 * tau_e * a_e_sorta^2)) +
  labs(title = "Including cementation")

ggarrange(p1,p2, p3, common.legend = TRUE, labels = "auto", legend = "right")
```  

Figure 3. Comparisons of physics-based models to measured permeability. a) Uses the Carman-Kozeny void fraction and the initial tortuosity and specific surface area expected from an uncompacted particle assemblage of the measured porosity and grain size. b) Considers compaction with the Panda-Lake (1994) model. c) Considers the impact of compaction and the effect of cementation on the tortuosity, following the Panda-Lake (1995) model.  

In addition to the two physics-based models, two regression-based models were tested (Fig. 4):  
1. A linear model using a Winland-style equation of the form
$$\ln k \propto \ln \phi_{CK} + \ln a_u + \ln \tau_e + \ln P_b + \ln P_f, $$  
2. A gradient boosting model using the same predictor variables, but assuming no particular functional form between the variables and permeability

```{r enet_training}
#, fig.width=5, fig.height=3
cl <- makePSOCKcluster(12)
registerDoParallel(cl)

## Elastic-net
grid_enet_lp <- expand.grid(
  alpha = seq(0, 1, length = 50),
  lambda = seq(0.0, 0.01, length = 6)
)

fit_enet_lp <- train(
  KLH ~ CK_void_fraction + a_u + tau_e + P_b + P_f,
  data = train_lp,
  method = 'glmnet',
  trControl = fit_control_lp,
  tuneGrid = grid_enet_lp
)

##ggplot(fit_enet_lp)

grid_enet_hp <- expand.grid(
  alpha = seq(0, 1, length = 50),
  lambda = seq(0.15, 0.2, length = 6)
)

fit_enet_hp <- train(
  KLH ~ CK_void_fraction + a_u + tau_e + P_b + P_f,
  data = train_hp,
  method = 'glmnet',
  trControl = fit_control_hp,
  tuneGrid = grid_enet_hp
)

#ggplot(fit_enet_hp)
```

```{r xgboost_training}
## XGBoost
cl <- makePSOCKcluster(12)
registerDoParallel(cl)

grid_lp <- expand.grid(
  nrounds = 700, #seq(100, 2000, by = 20),
  eta = 0.02,
  max_depth = 1,
  gamma = 0,
  colsample_bytree = 0.78,
  min_child_weight = 7,
  subsample = 1
)

fit_xgboost_lp <- train(
  logk ~ CK_void_fraction + tau_e + P_b + P_f,
  data = df_lowphi,
  method = 'xgbTree',
  trControl = fit_control_lp,
  tuneGrid = grid_lp
)
#ggplot(fit_xgboost_lp)
#fit_xgboost_lp$results %>% arrange(RMSE)

grid_hp <- expand.grid(
  nrounds = seq(40, 500, by = 10),
  max_depth = 1,
  eta = 0.015,
  gamma =  0.94,
  colsample_bytree = 0.69,
  min_child_weight = 7,
  subsample = 0.23
)

fit_xgboost_hp <- train(
  logk ~ CK_void_fraction + tau_e + P_b + P_f,
  data = df_highphi,
  method = 'xgbTree',
  trControl = fit_control_hp,
  tuneGrid = grid_hp
)
##ggplot(fit_xgboost_hp)
##fit_xgboost_hp$results %>% arrange(RMSE)
```

```{r model_results, fig.height=5.5, fig.width=7}

p1 <- 
  bind_rows(
  df_lowphi %>%
  mutate(
    Linear = exp(predict(fit_enet_lp,train_lp)),
    XGBoost = exp(predict(fit_xgboost_lp,.))),
  df_highphi %>%
    mutate(
      Linear = exp(predict(fit_enet_hp,train_hp)),
      XGBoost = exp(predict(fit_xgboost_hp, .)))
  )%>%
  gather("Model","k_pred", Linear, XGBoost ) %>%
  ggplot(aes(x = KLH, y = k_pred, color = porosity_group)) + 
  facet_wrap(~Model) +
  geom_point() +
  geom_abline(slope=1,intercept=0) +
  scale_color_manual("Porosity\ngroup",values = c("peru", "steelblue")) +
  annotation_logticks(sides = "bl") +
  scale_x_log10("Measured permeability (mD)", 
                breaks = c(0.1, 1, 10, 100, 1000),
                labels = c(0.1, 1, 10, 100, 1000)
                ) +
  scale_y_log10("Predicted permeability (mD)") 

#p1
p2 <- 
bind_rows(
  df_lowphi %>%
  mutate(
    Linear = resid(fit_enet_lp,train_lp),
    XGBoost = resid(fit_xgboost_lp,.)),
  df_highphi %>%
    mutate(
      Linear = resid(fit_enet_hp,train_hp),
      XGBoost = resid(fit_xgboost_hp, .))
  )%>%
  gather("Model","residual", Linear, XGBoost ) %>%
  ggplot(aes(x = KLH, y = residual, color = porosity_group)) + 
  facet_wrap(~Model) +
  geom_point() +
  geom_abline(slope=0,intercept=0) +
  scale_color_manual("Porosity\ngroup",values = c("peru", "steelblue")) +
  annotation_logticks(sides = "b") +
  scale_x_log10("Measured permeability (mD)", 
                breaks = c(0.1, 1, 10, 100, 1000),
                labels = c(0.1, 1, 10, 100, 1000)
                ) +
  scale_y_continuous("Residual in prediction (ln mD)") 

#p2
ggarrange(p1, p2, ncol =1, common.legend=TRUE, legend = "right", labels ="auto")


```

Figure 4. a) Predicted versus measured permeability using the linear and XGBoost models. b) Residuals in the predictions for the linear and XGBoost models. Color indicates whether the sample is in the high (greater than 5%) or low porosity group.  
  
As perhaps best shown by the residuals (Fig. 4b), the linear model is poor for the larger porosity group. The gold-colored points in Fig. 4b show a systematic over-prediction of permeability at smaller permeabilities (5 to 100 mD), while large permeability values (200 to 8000 mD) are over-predicted with the linear model.  

```{r winland_feature_importance, fig.width=5, fig.height=3}
importance_lp <- varImp(fit_enet_lp)$importance
importance_hp <- varImp(fit_enet_hp)$importance
importances <- as.data.frame(cbind( rownames(importance_lp), importance_lp, importance_hp))
importances[,1] = c("Carman-Kozeny void fraction", "Specific surface area", "Tortuosity","Pore-bridging cement", "Pore-filling cement")
colnames(importances) <- c("Feature", "Low", "High")
importances <- importances %>%
  gather("Low", "High", key="Porosity group", value="Importance")
ggplot(importances, aes(Feature, Importance, fill = `Porosity group`)) +
  geom_bar(stat="identity", position = "dodge") +
  coord_flip() +
  scale_fill_manual(values = c("peru", "steelblue"))

predictor = Predictor$new(fit_enet_lp, data = select(df, CK_void_fraction, tau_e, P_b, P_f, a_u), y = log(df$KLH))
imp = FeatureImp$new(predictor, loss = "rmse", n.repetitions = 40)
```

Figure 5. Feature importance for the linear model. color indicates whether the model was trained on high (greater than 5%) or low porosity samples. No bar indicates that the regularization procedure caused the weight for that feature to reach zero.

```{r xgboost_feature importance}
shaps_lp <- xgb.plot.shap(as.matrix(select(df_lowphi, CK_void_fraction, tau_e, P_b, P_f)), 
                       model=fit_xgboost_lp$finalModel, 
                       top_n=4, plot = FALSE)

shaps_hp <- xgb.plot.shap(as.matrix(select(df_highphi, CK_void_fraction, tau_e, P_b, P_f)), 
                       model=fit_xgboost_hp$finalModel, 
                       top_n=4, plot = FALSE)

data <- rbind(merge(melt(shaps_lp$shap_contrib, value.name="SHAP"),
              melt(shaps_lp$data, value.name="Value")
                    ) %>%
                mutate(`Porosity group`="Low"),
              merge(melt(shaps_hp$shap_contrib, value.name="SHAP"),
              melt(shaps_hp$data, value.name="Value")
                    ) %>%
                mutate(`Porosity group`="High")
)


ggarrange(
ggplot(filter(data, Var2=="CK_void_fraction"), aes(x=Value, y = SHAP, color=`Porosity group`)) +
  geom_point() +
  scale_x_log10() +
  scale_color_manual(values = c("peru","steelblue")) +
  labs(x = TeX("Void fraction, $\\phi_{CK}"))
,
ggplot(filter(data, Var2=="tau_e"), aes(x=Value, y = SHAP, color=`Porosity group`)) +
  geom_point() +
  scale_x_log10() +
  scale_color_manual(values = c("peru","steelblue")) +
  labs(x = TeX("Tortuosity, $\\tau_e"))
,
ggplot(filter(data, Var2=="P_f"), aes(x=Value, y = SHAP, color=`Porosity group`)) +
  geom_point() +
  scale_x_log10() +
  scale_color_manual(values = c("peru","steelblue")) +
  labs(x = TeX("Pore-filling cement, $P_f"))
,
ggplot(filter(data, Var2=="P_b"), aes(x=Value, y = SHAP, color=`Porosity group`)) +
  geom_point() +
  scale_x_log10() +
  scale_color_manual(values = c("peru","steelblue")) +
  labs(x = TeX("Pore-bridging cement, $P_b$"))
,
nrow = 2, ncol = 2, common.legend = TRUE)
```

Figure 6. Feature importance for the gradient boosting model, using SHAP. SHAP values show how much each element contributes to each prediction from the gradient boosting model. Orange dots show high porosity samples, while blue samples indicate low porosity samples.  
  
Table 2. Measures of model fitness for the XGBoost and linear models on the high porosity and low porosity groups for the training and testing data.
```{r model_fitness}

# model_fitness <- 
#   rbind(
#     postResample(log( predict(fit_xgboost_lp, df_lowphi)), log(df_lowphi$KLH)),
#     postResample(log( predict(fit_xgboost_lp, df_holdout_lp)), log(df_holdout_lp$KLH)),
#     
#     postResample(log( predict(fit_xgboost_hp, df_highphi)), log(df_highphi$KLH)),
#     postResample(log( predict(fit_xgboost_hp, df_holdout_hp)), log(df_holdout_hp$KLH)),
#     
#     postResample(log( predict(fit_enet_lp, train_lp)), (train_lp$KLH)),
#     postResample(log( predict(fit_enet_lp, test_lp)), (test_lp$KLH)),
#     
#     postResample(log( predict(fit_xgboost_hp, train_hp)), (train_hp$KLH)),
#     postResample(log( predict(fit_xgboost_hp, test_hp)), (test_hp$KLH))
#   ) %>%
#   as_tibble() %>%
#   round(2) %>%
#   rename(`R^2^`=Rsquared)
model_fitness <- 
  rbind(
    postResample(predict(fit_xgboost_lp, df_lowphi), log(df_lowphi$KLH)),
    postResample(predict(fit_xgboost_lp, df_holdout_lp), log(df_holdout_lp$KLH)),
    
    postResample(predict(fit_xgboost_hp, df_highphi), log(df_highphi$KLH)),
    postResample(predict(fit_xgboost_hp, df_holdout_hp), log(df_holdout_hp$KLH)),
    
    postResample(predict(fit_enet_lp, train_lp), train_lp$KLH),
    postResample(predict(fit_enet_lp, test_lp), test_lp$KLH),
    
    postResample(predict(fit_xgboost_hp, train_hp), train_hp$KLH),
    postResample(predict(fit_xgboost_hp, test_hp), test_hp$KLH)
  ) %>%
  as_tibble() %>%
  round(2) %>%
  rename(`R^2^`=Rsquared)

model_fitness$Model <- c("XGBoost","XGBoost","XGBoost","XGBoost",
                         "Linear","Linear","Linear","Linear")
model_fitness[,"Porosity group"] <- c("Low","Low","High","High",
                         "Low","Low","High","High")
model_fitness[,"Data"] <- c("Train","Test","Train","Test",
                         "Train","Test","Train","Test")

kable(model_fitness[,c("Model", "Porosity group","Data","RMSE","MAE","R^2^")],
      format="pandoc") #%>%
  #kable_styling()
```



# Discussion

1. Flat topped permeability for XGBoost from tree-based nature
2. We should mention the merits of dividing up the dataset relative to treating the data... en masse  


# Conclusions
This paper has the makings of greatness.

# References
Box, G. E. P., Cox, D.R., 1964. An analysis of transformation revisited, rebutted, Journal of the American Statistical Association, 77, pp. 209-210.   
Carman, P.C., 1937. Fluid flow through granular beds. Trans. Inst. Chem. Eng., 15, pp.150-166.  
Di, J. and Jensen, J.L., 2015. A closer look at pore throat size estimators for tight gas formations. Journal of Natural Gas Science and Engineering, 27, pp.1252-1260.  
Doyen, P.M., 1988. Permeability, conductivity, and pore geometry of sandstone. Journal of Geophysical Research: Solid Earth, 93(B7), pp.7729-7740.  
Dullien, F.A., 2012. _Porous media: fluid transport and pore structure_. Academic press.  
Ehrenberg, S.N., 1990. Relationship between diagenesis and reservoir quality in sandstones of the Garn formation, Haltenbanken, mid-Norwegian Continental shelf (1). AAPG bulletin, 74(10), pp.1538-1558.  
Fisher, A., Rudin, C. and Dominici, F., 2018. Model class reliance: Variable importance measures for any machine learning model class, from the “Rashomon” perspective. arXiv preprint arXiv:1801.01489.  
Frick, T.C., 1962. _Petroleum production handbook_ (Vol. 1). McGraw-Hill.  
Friedman, J.H., 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics, pp.1189-1232.  
Ghanbarian, B., Lake, L.W. and Sahimi, M., 2019. Insights into rock typing: a critical study. SPE Journal, 24(01), pp.230-242.  
Jensen, J. L., Hinkley, D. V., and Lake, L. W., 1987. A statistical study of reservoir permeability: Distributions, correlations, and averages. SPEFE, 2(6), pp. 461-468.  
Kolodzie Jr, S., 1980, January. Analysis of pore throat size and use of the Waxman-Smits equation to determine OOIP in Spindle Field, Colorado. Paper SPE 9382 in 55th SPE annual technical conference and exhibition. Society of Petroleum Engineers, 10p.  
Kozeny, J., 1927. Soil permeability. Sitzungsber. Oesterr. Akad. Wiss. Wien. Math. Naturwisss. Kl. Abt, 136, p.271.  
Lundberg, S.M., Erion, G.G. and Lee, S.I., 2018. Consistent individualized feature attribution for tree ensembles. arXiv preprint arXiv:1802.03888.  
Miller, R. G., 1986, _Beyond ANOVA, Basics of Applied Statistics_, J. Wiley and Sons, New York, 317p.  
Panda, M.N. and Lake, L.W., 1994. Estimation of single-phase permeability from parameters of particle-size distribution. AAPG bulletin, 78(7), pp.1028-1039.  
Panda, M.N. and Lake, L.W., 1995. A physical model of cementation and its effects on single-phase permeability. AAPG bulletin, 79(3), pp.431-443.  
Pettijohn, F. J., 1975, _Sedimentary Rocks_, Third Ed., Harper and Row, New York, 628p.  
Scheidegger, A.E., 1960, _The Physics of Flow Through Porous Media_, Revised Ed., University of Toronto Press.  
  
# Appendix A. Derivation of a modified Carman-Kozeny equation for uncemented sandstones
This section follows the derivation laid out by Panda and Lake (1994).

The derivation starts with the Carman-Kozeny equation 
$$k = \frac{\phi^3}{2\tau(1-\phi)^2 a^2},$$
where  permeability is $k$,  porosity is $\phi$, tortuosity is $\tau$, and the specific surface area is $a$. The porosity to Helium has been measured on the Garn data. Permeability to air that has been corrected for Klinkenberg effects is also part of the dataset. In order to estimate tortuosity and specific surface area, the dataset includes measurements of the median grain size and Trask sorting coefficient, following the approach proposed by Beard and Weyl (1973). Skewness of the distribution of grain sizes can be extracted from these parameters. 

Given this information, a modified Carman Kozeny equation following Panda and Lake (1994) is
$$k = \frac{\bar{D}^2 \phi^3}{72\tau_u \left(1-\phi \right)^2} \frac{\left(\gamma C_D^3 + 3C_D^2 +1 \right)^2}{\left(1+C_D^2\right)^2},$$
where $\bar{D}$ is the mean particle size, $C_D$ is the coefficient of varation of the particle size distribution ($C_D=\sigma_D/\bar{D}$), $\gamma$ is the skewness of the particle size distribution. and $\tau_u$ is the tortuosity of an unconsolidated, uncemented sand.  
  
Panda and Lake (1994) do not calculate the original tortuosity. However, there has been a wealth of work on this problem in the physics, soil, and petroleum literature. One approach is proposed by Ghanbarian, et al. (2013). This approach makes use of percolation theory and results in tortuosity following a power law with respect to porosity. Taking their equation 8 (which assumes reasonably well-sorted grains and a large system) and plugging in the relevant numbers, original tortuosity follows the equation
\begin{align}
\tau_o &= \left(\frac{\phi - \phi_t}{1 - \phi_t} \right)^{\nu(1-D)} \\
 &= \left(\frac{0.9\phi}{1-0.1\phi} \right)^{-0.378}
 \end{align}
Panda and Lake (1995) use a surface area argument to derive the effective tortuosity for an uncemented sandstone of different size particles, which is
$$\tau_u = \tau_o \left(1 + C_D^2 \right).$$
Tthe distributions of the grain distribution measures, $\bar D,\ C_D$, $\gamma$, and the tortuosity $\tau_u$ are given in Fig. A1. These measures are all highly skewed.
```{r distribution, warning=FALSE}


# ggarrange(
# 
# ggplot(df, aes(sample=GS)) +
#   geom_qq() +
#   scale_y_log10()+#limits=c(,1)) +
#   labs(x = "Theoretical quantile",y="Median grain size (micron)"),
# 
# ggplot(df, aes(sample=SO)) +
#   geom_qq() +
#   scale_y_continuous(limits = c(1,2)) +
#   #scale_y_log10(limits= c(1,3))
#   labs(x = "Theoretical quantile", y="Trask sorting coefficient"),
# ncol = 2, nrow=1)

plot_hist_linear <- function(x, bins = 20){
  x <- ensym(x)
  p <- ggplot(df, aes(x = !!x)) +
    geom_histogram(fill="steelblue", bins = bins) +
    #annotation_logticks(sides = "b") +
    scale_y_continuous("Count", expand = c(0.001,0))
  p
}

ggarrange(

  plot_hist_linear(mean_GS, bins = 10) +
    labs(x="Mean grain size (micron)")
  ,

plot_hist(Cv_GS, bins = 10) +
  scale_x_log10() +
  labs(x=TeX("$C_v$ of grain size")),

plot_hist(gamma_GS, bins = 10) +
  scale_x_log10() +
  labs(x = TeX("$\\gamma$ of grain size")),

plot_hist(tau_u, bins = 10) +
  scale_x_log10() +
  labs(x = "Tortuosity before cementation"),
ncol = 2, nrow = 2)

```
Figure A1. Histograms of several grain properties.

<!-- Now, how well did it work? -->

<!-- ```{r panda_lake_1994, warning=FALSE} -->
<!-- #df <- mutate(df,  -->
<!-- #             k_pl94 = (mean_GS^2 * POR^3)/(72* tortuosity_u) * (gamma_GS * Cv_GS^3 + 3*Cv_GS^2 + 1)^2/(1 + Cv_GS^2)^2) -->

<!-- ggplot(df,aes(x=k_pl94_por, y=KLH) ) + -->
<!--   geom_point() + -->
<!--   geom_smooth(method="rlm", color="steelblue") + -->
<!--   geom_abline(slope=1, intercept=0, color="peru") + -->
<!--   scale_x_log10("Predicted permeability before cementation (mD)", breaks = c(1,10,100,1000,10000, 100000)) + -->
<!--   scale_y_log10("Measured permeability (mD)", limits=c(0.1,2e3), breaks = c(1,10,100,1000,10000))  -->

<!-- ggplot(df,aes(x=k_pl94_impor, y=KLH) ) + -->
<!--   geom_point() + -->
<!--   geom_smooth(method="rlm", color="steelblue") + -->
<!--   geom_abline(slope=1, intercept=0, color="peru") + -->
<!--   scale_x_log10("Predicted permeability before cementation using interparticle macroporosity (mD)") + #, breaks = c(1,10,100,1000,10000, 100000)) + -->
<!--   scale_y_log10("Measured permeability (mD)", limits=c(0.1,2e3), breaks = c(1,10,100,1000,10000))  -->

<!-- summary( -->
<!--   rlm(log(KLH) ~ log(k_pl94_por), df) -->
<!-- ) -->
<!-- cor.test(df$k_pl94_por,df$KLH, method='spearman' )$estimate**2 -->
<!-- ``` -->

# Appendix B: Derivation of Carman-Kozeny corrections for cemented sandstones
This section follows the derivation laid out by Panda and Lake (1995).  
  
Carman-Kozeny theory does not consider the effect of cementation on permeability, but cement is present in these rocks, and it blocks flow paths, decreasing the rock permeability. In terms of the quantities considered by Carman and Kozeny, this changes the tortuosity and the specific surface area. There are several different cements that are be present, and they are measured through point counting.  
  
Panda and Lake (1995) separate cement types into three categories: pore-filling, pore-lining, and pore-briding, following Neasham (1997). Where cements associate with the pores depends on the thermodynamic properties of the cementing material. Crystal-like kaolinite and dickite cements are pore-filling. Other pore-filling cements include quartz, feldspar, dolomite, and calcite. These cements affect the porosity, but because they do not affect the pore throats or the pore shape, under this model they have a small effect on permeability.  
  
Pore-lining cements find it energetically favorable to form long crystals that stretch out from the grains. These cements include the non-kaolinite clay minerals, such as chlorite, illite, and smectite. The long crystals affect permeability more than they affect porosity because of the large surface areas they generate.  
    
Pore-bridging cements can partially or completely block the pore throats. This strongly influences the permeability through increasing the tortuosity of the system and decreasing the connectivity. Examples of the minerals that bridge pores include illite, chlorite, and montmorillonite (the non-Kaolin clay minerals).  
    
After cementation, the tortuosity and specific surface area has changed. Panda and Lake (1995) suggest an effective tortuosity, $\tau_e$, given by
$$\tau_e = \tau_u \left(1+C_D^2 \right)\left(1+\frac{Rm_b}{1-m_b} \right)^2 \left(1 + \frac{2m}{(1-m) \phi^{1/3}} \right)^2,$$
where $R$ is a constant equal to 2 indicating the additional distance traveled by the fluid as a function of the thickness of cementation. The volume fraction of pore-bridging cement is $m_b = P_b(1-\phi)/\phi$, and the volume fraction of pore-filling cement is $m = P_f (1-\phi)/\phi$.  
    
For an unconsolidated sand of variable sizes, the specific surface area is
$$a_u = \frac{6(\sigma^2 + \bar{D}^2)}{\gamma \sigma^3 + 3\bar{D}\sigma^2 + \bar{D}^3}$$
After cementation, the effective specific surface area follows the equation
$$a_e = a_u \frac{1-\phi_u}{1-\phi} + a_b P_b + a_f P_f$$
where $a_u$ is the specific surface area for an unconsolidated, uncemented sand, $\phi_u$ is the porosity of an unconsolidated sand, $a_b$ is the specific surface area for a pore-bridging cement, $a_f$ is the specific surface area for a pore-filling cement, and $P_b,P_f$ are the relative fractions of pore-bridging and pore-filling cement, respectively.  
    
Taking these equations together, the equation for permeability becomes
$$k = \left[\bar{D}^2 \phi^3 \left(\gamma C_D^3 + 3C_D^2 + 1 \right)^2 \right]
 \left\{ 2\tau_e (1-\phi)^2 \left[ 6\left(1+C_D^2 \right) \frac{1-\phi_u}{1-\phi} + 
 \left(a_b P_b + a_f P_f \right) \bar{D} \left(\gamma C_D^3 + 3C_D^2 +1 \right) \right]^2\right\}^{-1}$$
Now, with these calculations, the properties of the grain size distribution measured by Ehrenberg (1990) can be used to test the theory derived by Panda and Lake (1995).

<!-- \begin{align} -->
<!-- k &= \left[\bar{D}^2 \phi^3 \left(3C_D^2 + 1 \right)^2 \right]\\ -->
<!--  &\left\{ 2\tau_e (1-\phi)^2 \left[ 6\left(1+C_D^2 \right) \frac{1-\phi_u}{1-\phi} +\right.\right.\\ -->
<!--  &\left.\left. \left(a_b P_b + a_f P_f \right) \bar{D} \left(3C_D^2 +1 \right) \right]^2\right\}^{-1} -->
<!-- \end{align} -->

# Appendix C: Lognormal distribution statistics
In this appendix we relate median grain size and the Trask Sorting Coefficient ($S_o$) to the mean, standard deviation, and skewness of the grain size distribution. From the mean and standard deviation, the coefficient of variation, $C_v = \bar{D}/\sigma$, can be calculated.

Grain size distribution is often described by the median grain size and the Trask Sorting Coefficient ($S_o$), which is defined by $S_o=\sqrt{D_{0.75}/D_{0.25}}$, where $D_p$ is the quantile value indicated by $p$, such that $D_{0.25}$ is the 25%-ile grain size. Panda (1994, Appendix B) derived an equation relating average grain size, Trask Sorting Coefficient, and the standard deviation of the grain size, which is
\begin{equation}
\sigma = \bar{D} \frac{S_o^2-1}{0.675\left(S_o^2+1\right)}.
\end{equation}
This equation assumes that $D_p$ is calculated from the distribution of grain sizes in $\log_2$ space, but most calculations of $S_o$ use the definition provided above, so this should be re-derived.  

A new derivation, assuming lognormaly distributed grain sizes, can be described with the PDF
\begin{equation}
\frac{1}{x\sigma\sqrt{2\pi}} \exp\left(-\frac{(\ln x-\mu)^2}{2\sigma^2} \right),
\end{equation}
the mean grain size is $\bar{D} = \exp(\mu + \sigma/2)$, and in terms of the median and Trask sorting coefficient, the parameters of the distribution are
$$\begin{align}
\mu &= \ln D_{0.5}\\
\sigma &= \frac{\ln S_o}{\sqrt{2}\ \text{erf}^{-1}(0.5)}
\end{align}$$

Simple R code to test these statistics is given below. It generates numbers from a random lognormal distribution:
```{r lognormal_stats, echo=TRUE}
mu <- 3.14159
sigma <- 1
d <- rlnorm(10000, mu, sigma) # distribution of 1k points with mu=10, sigma=1

trask <- sqrt(quantile(d,0.75) / quantile(d,0.25))
d_50 <- median(d)
mu_calc <- log(d_50)
erfinv <- function(x) qnorm((x + 1)/2)/sqrt(2)
sigma_calc <- log(trask) / (sqrt(2) * erfinv(0.5))
mean_calc <- exp(log(d_50) + sigma_calc/2)
exponent_thingie <- (2*sqrt(2) * erfinv(0.5))

cat(
  "\nThe median is", round(median(d),1),
       "It should be", round(exp(mu),1),
      "\nThe mean is",round(mean(d),1),
      "It should be", round(exp(mu + sigma/2),1),
      "\nThe standard deviation is",round(sd(d),1),
      "It should be",round( sqrt( (exp(sigma^2)-1) * exp(2*mu+sigma^2))),
      "\nThe Trask sorting coefficient is",round(sqrt(quantile(d,0.75) / quantile(d,0.25)),2),
  "\nFrom the Trask and median diameters, the mean should be", round(mean_calc,1),"or",
  round(d_50 * trask^(1/(2*sqrt(2) * erfinv(0.5))),1),
  "\nThis is a deviation of", round((exp(mu + sigma/2) - mean_calc)/exp(mu + sigma/2)*100,1),"percent\n"
      
)
```

The mean grain size can be calculated from the median grain size and standard deviation through the equation (assuming a lognormal distribution of the grain size). In addition, the coefficient of variation and skewness can be calculated. The equations for these terms are
$$\begin{align}
\bar{D} &= \exp \left[ \ln(D_{\text{0.5}}) + \sigma/2 \right] &
        &= D_{0.5} S_o^{1/{(2\sqrt{2}\ \text{erf}^{-1}(0.5)})} &
        &= D_{0.5} S_o^{1.349}\\
C_D &= \sqrt{e^{\sigma^2}-1} &
    &= \sqrt{e^{2.198(\ln S_o)^2} -1} & \\
\gamma &= \left(e^{\sigma^2} + 2\right) \sqrt{e^{\sigma^2}-1} &
       &= \left(e^{\sigma^2} + 2\right) C_D  &\\
       &= \left( e^{2.198(\ln S_o)^2} + 2\right)\sqrt{e^{2.198(\ln S_o)^2} -1}
\end{align}$$
These equations are used in this manuscript to determine the Carman Kozeny coefficients for each sample.